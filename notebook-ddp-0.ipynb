{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59f8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "!#!pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8cce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /data/runs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d5e6b0",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40366c6d",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1624759889299,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "02d1a0c0"
   },
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cecc3e1",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ecb88a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36c3097c",
   "metadata": {
    "id": "073b7b81"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e04251c",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet152'\n",
    "EPOCHS = 5\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=256\n",
    "VAL_BATCH=256\n",
    "WORKERS=2\n",
    "TRAINDIR=\"/data/CINIC/train\"\n",
    "VALDIR=\"/data/CINIC/valid\"\n",
    "GPU=\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd4af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your active device to your GPU in this cell\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed1acad0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1622949197302,
     "user": {
      "displayName": "Jayanth Srinivasa",
      "photoUrl": "",
      "userId": "03369694624178485882"
     },
     "user_tz": 420
    },
    "id": "c6bf6a83",
    "outputId": "72d2e92f-7574-4c0a-c813-288cd69eaa36"
   },
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6ef17c3",
   "metadata": {
    "id": "acd97390"
   },
   "outputs": [],
   "source": [
    "#torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1df67d8",
   "metadata": {
    "id": "e19a5849"
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31de91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(ip, rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = ip\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "180df28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f490738",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = '172.31.5.57'\n",
    "world_size = 2\n",
    "rank = 0\n",
    "setup(ip, rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a00b15c1",
   "metadata": {
    "id": "4e65743f"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    global_step = 0\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "#         if GPU is not None:\n",
    "#             images = images.cuda(GPU, non_blocking=True)\n",
    "#         if torch.cuda.is_available():\n",
    "#             target = target.cuda(GPU, non_blocking=True)\n",
    "        images = images.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Enables autocasting for the forward pass (model + loss)\n",
    "        with torch.autocast(device_type=device):\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            writer.add_scalar(\"accuracy/acc1\", acc1, global_step)\n",
    "            writer.add_scalar(\"accuracy/acc5\", acc5, global_step)\n",
    "            writer.add_scalar(\"loss\", loss, global_step)\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # compute gradient and do SGD step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "            global_step += 1\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa67794b",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "#             if GPU is not None:\n",
    "#                 images = images.cuda(GPU, non_blocking=True)\n",
    "#             if torch.cuda.is_available():\n",
    "#                 target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            with torch.autocast(device_type=device):\n",
    "                output = model(images)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "                # measure accuracy and record loss\n",
    "                acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "                losses.update(loss.item(), images.size(0))\n",
    "                top1.update(acc1[0], images.size(0))\n",
    "                top5.update(acc5[0], images.size(0))\n",
    "\n",
    "                # measure elapsed time\n",
    "                batch_time.update(time.time() - end)\n",
    "                end = time.time()\n",
    "\n",
    "                if i % PRINT_FREQ == 0:\n",
    "                    progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "620e1b66",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03bba151",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfc783e8",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9592cf1",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab96ddd7",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54d6c45e",
   "metadata": {
    "id": "f74f06e1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87cab721",
   "metadata": {
    "id": "c005e2dd"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=cifar_mean_RGB, std=cifar_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ed6b949",
   "metadata": {
    "id": "29d54592"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "# IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e68de52",
   "metadata": {
    "id": "94059b7f"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e908b70",
   "metadata": {
    "id": "788c0401"
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()\n",
    "#model = models.resnet152(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fed1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a908ab44",
   "metadata": {
    "id": "63dc579e"
   },
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c452ead",
   "metadata": {
    "id": "edf9cf5d"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44f2e3d3",
   "metadata": {
    "id": "319e2d99"
   },
   "outputs": [],
   "source": [
    "#model.cuda(GPU)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f218bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DDP(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e23d5a0c",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c50934f",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67c36b87",
   "metadata": {
    "id": "9fae338b"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4458bc8",
   "metadata": {
    "id": "34dbcdb1"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6daab90b",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "610a1782",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cinic_mean_RGB, cinic_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34d12427",
   "metadata": {
    "id": "abfa5fb6"
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a6298ae",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=True,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5783f75",
   "metadata": {
    "id": "192ae835"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84b17952",
   "metadata": {
    "id": "1502c5db"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde0993",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  0/352]\tTime  4.929 ( 4.929)\tData  0.207 ( 0.207)\tLoss 9.6879e+00 (9.6879e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n",
      "Epoch: [0][ 50/352]\tTime  1.423 ( 0.893)\tData  0.001 ( 0.005)\tLoss nan (nan)\tAcc@1  10.16 (  9.56)\tAcc@5  48.83 ( 48.70)\n",
      "Epoch: [0][100/352]\tTime  1.337 ( 0.871)\tData  0.001 ( 0.003)\tLoss nan (nan)\tAcc@1  10.55 (  9.78)\tAcc@5  44.53 ( 49.67)\n",
      "Epoch: [0][150/352]\tTime  1.364 ( 0.859)\tData  0.001 ( 0.002)\tLoss nan (nan)\tAcc@1   9.77 (  9.71)\tAcc@5  53.52 ( 49.72)\n",
      "Epoch: [0][200/352]\tTime  1.365 ( 0.857)\tData  0.001 ( 0.002)\tLoss nan (nan)\tAcc@1  11.33 (  9.79)\tAcc@5  53.12 ( 49.62)\n",
      "Epoch: [0][250/352]\tTime  1.191 ( 0.853)\tData  0.001 ( 0.002)\tLoss nan (nan)\tAcc@1  10.94 (  9.96)\tAcc@5  50.00 ( 49.93)\n",
      "Epoch: [0][300/352]\tTime  1.082 ( 0.850)\tData  0.001 ( 0.001)\tLoss nan (nan)\tAcc@1  10.55 (  9.94)\tAcc@5  42.97 ( 49.85)\n",
      "Epoch: [0][350/352]\tTime  1.415 ( 0.850)\tData  0.000 ( 0.001)\tLoss nan (nan)\tAcc@1  12.50 (  9.95)\tAcc@5  52.73 ( 49.89)\n",
      "Batch size: 256, allocated memory: 2466.3974609375 MB total memory: 22592.0625 MB\n",
      "Test: [  0/352]\tTime  0.231 ( 0.231)\tLoss nan (nan)\tAcc@1   0.00 (  0.00)\tAcc@5 100.00 (100.00)\n",
      "Test: [ 50/352]\tTime  0.091 ( 0.060)\tLoss nan (nan)\tAcc@1 100.00 ( 31.07)\tAcc@5 100.00 (100.00)\n",
      "Test: [100/352]\tTime  0.089 ( 0.059)\tLoss nan (nan)\tAcc@1   0.00 ( 34.81)\tAcc@5 100.00 (100.00)\n",
      "Test: [150/352]\tTime  0.091 ( 0.058)\tLoss nan (nan)\tAcc@1   0.00 ( 23.28)\tAcc@5 100.00 (100.00)\n",
      "Test: [200/352]\tTime  0.090 ( 0.058)\tLoss nan (nan)\tAcc@1   0.00 ( 17.49)\tAcc@5   0.00 ( 87.45)\n",
      "Test: [250/352]\tTime  0.088 ( 0.058)\tLoss nan (nan)\tAcc@1   0.00 ( 14.01)\tAcc@5   0.00 ( 70.03)\n",
      "Test: [300/352]\tTime  0.091 ( 0.058)\tLoss nan (nan)\tAcc@1   0.00 ( 11.68)\tAcc@5   0.00 ( 58.40)\n",
      "Test: [350/352]\tTime  0.087 ( 0.058)\tLoss nan (nan)\tAcc@1   0.00 ( 10.02)\tAcc@5   0.00 ( 50.08)\n",
      " * Acc@1 10.000 Acc@5 50.000\n",
      "lr: [0.09045084971874738]\n",
      "Epoch: [1][  0/352]\tTime  0.540 ( 0.540)\tData  0.201 ( 0.201)\tLoss nan (nan)\tAcc@1  11.33 ( 11.33)\tAcc@5  50.78 ( 50.78)\n",
      "Epoch: [1][ 50/352]\tTime  1.111 ( 0.802)\tData  0.001 ( 0.005)\tLoss nan (nan)\tAcc@1   7.81 ( 10.23)\tAcc@5  50.39 ( 49.73)\n",
      "Epoch: [1][100/352]\tTime  1.597 ( 0.832)\tData  0.001 ( 0.003)\tLoss nan (nan)\tAcc@1  10.16 ( 10.23)\tAcc@5  52.34 ( 50.17)\n",
      "Epoch: [1][150/352]\tTime  2.096 ( 0.953)\tData  0.001 ( 0.002)\tLoss nan (nan)\tAcc@1   7.81 ( 10.16)\tAcc@5  44.14 ( 50.01)\n"
     ]
    }
   ],
   "source": [
    "# Create a SummaryWriter to log accuracy, loss, and learning rate during training\n",
    "writer = SummaryWriter(log_dir=\"/data/runs/\")\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # Check how much GPU memory was used during training\n",
    "    allocated_memory = torch.cuda.max_memory_allocated(device=device)\n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "    print(f\"Batch size: {TRAIN_BATCH}, allocated memory: {allocated_memory / 1024 / 1024} MB total memory: {total_memory / 1024 / 1024} MB\")\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "# Close the SummaryWriter\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565e66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a4faf",
   "metadata": {
    "id": "adc68068"
   },
   "outputs": [],
   "source": [
    "# the logdir should match the parameter passed to what you pass to SummaryWriter, e.g.\n",
    "# writer = SummaryWriter(log_dir=\"/data/runs/\")\n",
    "#!tensorboard --logdir=/data/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f82034",
   "metadata": {
    "id": "d3faf0cd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
