{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da270e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /data/runs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bfe2b34",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197c3c1e",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1624759889299,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "02d1a0c0"
   },
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b9d3672",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "254619a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "201d6beb",
   "metadata": {
    "id": "073b7b81"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b09b025e",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet152'\n",
    "EPOCHS = 5\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=512\n",
    "VAL_BATCH=512\n",
    "WORKERS=2\n",
    "#TRAINDIR=\"/data/CINIC/train\"\n",
    "#VALDIR=\"/data/CINIC/valid\"\n",
    "TRAINDIR=\"/data/train\"\n",
    "VALDIR=\"/data/val\"\n",
    "GPU=\"cuda:0\"\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adc4b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your active device to your GPU in this cell\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3bf0200",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1622949197302,
     "user": {
      "displayName": "Jayanth Srinivasa",
      "photoUrl": "",
      "userId": "03369694624178485882"
     },
     "user_tz": 420
    },
    "id": "c6bf6a83",
    "outputId": "72d2e92f-7574-4c0a-c813-288cd69eaa36"
   },
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d53595b1",
   "metadata": {
    "id": "acd97390"
   },
   "outputs": [],
   "source": [
    "#torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41969f71",
   "metadata": {
    "id": "e19a5849"
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de663a12",
   "metadata": {
    "id": "4e65743f"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    global_step = 0\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "#         if GPU is not None:\n",
    "#             images = images.cuda(GPU, non_blocking=True)\n",
    "#         if torch.cuda.is_available():\n",
    "#             target = target.cuda(GPU, non_blocking=True)\n",
    "        images = images.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Enables autocasting for the forward pass (model + loss)\n",
    "        #with torch.autocast(device_type=device):\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        writer.add_scalar(\"accuracy/acc1\", acc1, global_step)\n",
    "        writer.add_scalar(\"accuracy/acc5\", acc5, global_step)\n",
    "        writer.add_scalar(\"loss\", loss, global_step)\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        global_step += 1\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1218726d",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "#             if GPU is not None:\n",
    "#                 images = images.cuda(GPU, non_blocking=True)\n",
    "#             if torch.cuda.is_available():\n",
    "#                 target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            with torch.autocast(device_type=device):\n",
    "                output = model(images)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "                # measure accuracy and record loss\n",
    "                acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "                losses.update(loss.item(), images.size(0))\n",
    "                top1.update(acc1[0], images.size(0))\n",
    "                top5.update(acc5[0], images.size(0))\n",
    "\n",
    "                # measure elapsed time\n",
    "                batch_time.update(time.time() - end)\n",
    "                end = time.time()\n",
    "\n",
    "                if i % PRINT_FREQ == 0:\n",
    "                    progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24fa7c61",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3501f5e",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6009016a",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99226911",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61dde14e",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "715c676f",
   "metadata": {
    "id": "f74f06e1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "577ad9dc",
   "metadata": {
    "id": "c005e2dd"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2024e77",
   "metadata": {
    "id": "29d54592"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "#IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9075905",
   "metadata": {
    "id": "94059b7f"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17f8c363",
   "metadata": {
    "id": "788c0401"
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()\n",
    "#model = models.resnet152(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fff8add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c7b5cff",
   "metadata": {
    "id": "63dc579e"
   },
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af833c7f",
   "metadata": {
    "id": "edf9cf5d"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7273440",
   "metadata": {
    "id": "319e2d99"
   },
   "outputs": [],
   "source": [
    "#model.cuda(GPU)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d446fd9c",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7f42507",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b7db36c",
   "metadata": {
    "id": "9fae338b"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f12e6c3a",
   "metadata": {
    "id": "34dbcdb1"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "187aacc8",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ff4fa94",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a85c2e8",
   "metadata": {
    "id": "abfa5fb6"
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9bcdf031",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=True,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f93cecce",
   "metadata": {
    "id": "192ae835"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c7cd0b5",
   "metadata": {
    "id": "1502c5db"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8b3105f",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/2503]\tTime  4.072 ( 4.072)\tData  2.154 ( 2.154)\tLoss 9.5584e+00 (9.5584e+00)\tAcc@1   0.20 (  0.20)\tAcc@5   0.20 (  0.20)\n",
      "Epoch: [0][  50/2503]\tTime  2.033 ( 1.037)\tData  1.925 ( 0.892)\tLoss 9.2216e+00 (9.8735e+00)\tAcc@1   0.00 (  0.10)\tAcc@5   0.20 (  0.55)\n",
      "Epoch: [0][ 100/2503]\tTime  1.943 ( 1.042)\tData  1.835 ( 0.914)\tLoss 7.3770e+00 (8.7882e+00)\tAcc@1   0.00 (  0.09)\tAcc@5   0.59 (  0.53)\n",
      "Epoch: [0][ 150/2503]\tTime  1.923 ( 1.039)\tData  1.815 ( 0.918)\tLoss 7.1393e+00 (8.2844e+00)\tAcc@1   0.00 (  0.09)\tAcc@5   0.20 (  0.53)\n",
      "Epoch: [0][ 200/2503]\tTime  2.030 ( 1.038)\tData  1.922 ( 0.920)\tLoss 7.1445e+00 (8.0102e+00)\tAcc@1   0.78 (  0.10)\tAcc@5   0.98 (  0.54)\n",
      "Epoch: [0][ 250/2503]\tTime  1.842 ( 1.035)\tData  1.734 ( 0.918)\tLoss 7.0709e+00 (7.8366e+00)\tAcc@1   0.00 (  0.11)\tAcc@5   0.39 (  0.54)\n",
      "Epoch: [0][ 300/2503]\tTime  1.805 ( 1.032)\tData  1.697 ( 0.917)\tLoss 7.1016e+00 (7.7171e+00)\tAcc@1   0.00 (  0.10)\tAcc@5   0.59 (  0.54)\n",
      "Epoch: [0][ 350/2503]\tTime  1.948 ( 1.035)\tData  1.840 ( 0.921)\tLoss 7.1018e+00 (7.6312e+00)\tAcc@1   0.00 (  0.10)\tAcc@5   1.17 (  0.55)\n",
      "Epoch: [0][ 400/2503]\tTime  1.966 ( 1.039)\tData  1.858 ( 0.926)\tLoss 7.2701e+00 (7.5649e+00)\tAcc@1   0.20 (  0.11)\tAcc@5   0.78 (  0.56)\n",
      "Epoch: [0][ 450/2503]\tTime  1.903 ( 1.042)\tData  1.796 ( 0.929)\tLoss 7.1597e+00 (7.5247e+00)\tAcc@1   0.20 (  0.11)\tAcc@5   0.78 (  0.58)\n",
      "Epoch: [0][ 500/2503]\tTime  1.935 ( 1.045)\tData  1.828 ( 0.932)\tLoss 7.2081e+00 (7.4916e+00)\tAcc@1   0.39 (  0.12)\tAcc@5   0.59 (  0.61)\n",
      "Epoch: [0][ 550/2503]\tTime  2.018 ( 1.045)\tData  1.911 ( 0.933)\tLoss 7.1085e+00 (7.4571e+00)\tAcc@1   0.39 (  0.13)\tAcc@5   1.17 (  0.64)\n",
      "Epoch: [0][ 600/2503]\tTime  1.999 ( 1.047)\tData  1.891 ( 0.935)\tLoss 7.0815e+00 (7.4238e+00)\tAcc@1   0.00 (  0.13)\tAcc@5   0.78 (  0.68)\n",
      "Epoch: [0][ 650/2503]\tTime  1.978 ( 1.047)\tData  1.870 ( 0.936)\tLoss 6.8606e+00 (7.3889e+00)\tAcc@1   0.59 (  0.15)\tAcc@5   1.17 (  0.72)\n",
      "Epoch: [0][ 700/2503]\tTime  1.892 ( 1.047)\tData  1.784 ( 0.936)\tLoss 6.9088e+00 (7.3559e+00)\tAcc@1   0.20 (  0.16)\tAcc@5   1.56 (  0.78)\n",
      "Epoch: [0][ 750/2503]\tTime  2.017 ( 1.048)\tData  1.910 ( 0.937)\tLoss 6.8473e+00 (7.3251e+00)\tAcc@1   0.00 (  0.17)\tAcc@5   1.95 (  0.82)\n",
      "Epoch: [0][ 800/2503]\tTime  2.193 ( 1.048)\tData  2.086 ( 0.937)\tLoss 6.8753e+00 (7.2969e+00)\tAcc@1   0.20 (  0.17)\tAcc@5   0.98 (  0.85)\n",
      "Epoch: [0][ 850/2503]\tTime  1.913 ( 1.048)\tData  1.806 ( 0.937)\tLoss 6.8495e+00 (7.2713e+00)\tAcc@1   0.20 (  0.18)\tAcc@5   1.17 (  0.88)\n",
      "Epoch: [0][ 900/2503]\tTime  1.911 ( 1.048)\tData  1.803 ( 0.937)\tLoss 6.8585e+00 (7.2470e+00)\tAcc@1   0.59 (  0.19)\tAcc@5   1.76 (  0.91)\n",
      "Epoch: [0][ 950/2503]\tTime  0.889 ( 1.047)\tData  0.781 ( 0.937)\tLoss 6.8555e+00 (7.2250e+00)\tAcc@1   0.00 (  0.20)\tAcc@5   0.98 (  0.94)\n",
      "Epoch: [0][1000/2503]\tTime  0.813 ( 1.048)\tData  0.706 ( 0.937)\tLoss 6.7650e+00 (7.2043e+00)\tAcc@1   0.20 (  0.21)\tAcc@5   2.73 (  0.98)\n",
      "Epoch: [0][1050/2503]\tTime  1.452 ( 1.048)\tData  1.345 ( 0.938)\tLoss 6.8187e+00 (7.1842e+00)\tAcc@1   0.39 (  0.22)\tAcc@5   0.98 (  1.03)\n",
      "Epoch: [0][1100/2503]\tTime  1.288 ( 1.049)\tData  1.180 ( 0.939)\tLoss 6.7669e+00 (7.1646e+00)\tAcc@1   0.20 (  0.23)\tAcc@5   2.15 (  1.07)\n",
      "Epoch: [0][1150/2503]\tTime  1.058 ( 1.049)\tData  0.950 ( 0.939)\tLoss 6.7213e+00 (7.1460e+00)\tAcc@1   0.00 (  0.24)\tAcc@5   1.95 (  1.11)\n",
      "Epoch: [0][1200/2503]\tTime  0.786 ( 1.048)\tData  0.678 ( 0.938)\tLoss 6.6800e+00 (7.1273e+00)\tAcc@1   0.20 (  0.26)\tAcc@5   2.34 (  1.16)\n",
      "Epoch: [0][1250/2503]\tTime  0.349 ( 1.048)\tData  0.242 ( 0.938)\tLoss 6.6456e+00 (7.1099e+00)\tAcc@1   0.20 (  0.27)\tAcc@5   1.76 (  1.20)\n",
      "Epoch: [0][1300/2503]\tTime  0.110 ( 1.048)\tData  0.000 ( 0.938)\tLoss 6.6402e+00 (7.0925e+00)\tAcc@1   0.98 (  0.28)\tAcc@5   1.95 (  1.25)\n",
      "Epoch: [0][1350/2503]\tTime  0.790 ( 1.049)\tData  0.682 ( 0.939)\tLoss 6.5639e+00 (7.0757e+00)\tAcc@1   0.20 (  0.29)\tAcc@5   2.15 (  1.29)\n",
      "Epoch: [0][1400/2503]\tTime  0.110 ( 1.049)\tData  0.000 ( 0.939)\tLoss 6.5587e+00 (7.0591e+00)\tAcc@1   0.59 (  0.30)\tAcc@5   3.12 (  1.35)\n",
      "Epoch: [0][1450/2503]\tTime  0.110 ( 1.049)\tData  0.000 ( 0.940)\tLoss 6.5391e+00 (7.0431e+00)\tAcc@1   1.37 (  0.32)\tAcc@5   4.49 (  1.40)\n",
      "Epoch: [0][1500/2503]\tTime  0.109 ( 1.050)\tData  0.000 ( 0.940)\tLoss 6.5428e+00 (7.0274e+00)\tAcc@1   0.20 (  0.33)\tAcc@5   2.93 (  1.46)\n",
      "Epoch: [0][1550/2503]\tTime  0.109 ( 1.050)\tData  0.000 ( 0.940)\tLoss 6.5086e+00 (7.0126e+00)\tAcc@1   0.78 (  0.34)\tAcc@5   3.32 (  1.51)\n",
      "Epoch: [0][1600/2503]\tTime  0.109 ( 1.049)\tData  0.000 ( 0.940)\tLoss 6.5918e+00 (6.9985e+00)\tAcc@1   0.98 (  0.36)\tAcc@5   3.52 (  1.57)\n",
      "Epoch: [0][1650/2503]\tTime  0.111 ( 1.049)\tData  0.000 ( 0.940)\tLoss 6.4774e+00 (6.9850e+00)\tAcc@1   0.59 (  0.37)\tAcc@5   4.30 (  1.62)\n",
      "Epoch: [0][1700/2503]\tTime  0.110 ( 1.049)\tData  0.000 ( 0.940)\tLoss 6.5738e+00 (6.9720e+00)\tAcc@1   0.39 (  0.38)\tAcc@5   2.73 (  1.66)\n",
      "Epoch: [0][1750/2503]\tTime  0.109 ( 1.049)\tData  0.000 ( 0.940)\tLoss 6.5158e+00 (6.9593e+00)\tAcc@1   0.98 (  0.40)\tAcc@5   3.91 (  1.71)\n",
      "Epoch: [0][1800/2503]\tTime  0.110 ( 1.049)\tData  0.000 ( 0.940)\tLoss 6.5556e+00 (6.9473e+00)\tAcc@1   1.17 (  0.41)\tAcc@5   4.10 (  1.77)\n",
      "Epoch: [0][1850/2503]\tTime  0.109 ( 1.049)\tData  0.000 ( 0.940)\tLoss 6.4793e+00 (6.9355e+00)\tAcc@1   0.78 (  0.42)\tAcc@5   4.49 (  1.82)\n",
      "Epoch: [0][1900/2503]\tTime  0.110 ( 1.050)\tData  0.000 ( 0.940)\tLoss 6.5279e+00 (6.9240e+00)\tAcc@1   0.20 (  0.44)\tAcc@5   3.12 (  1.87)\n",
      "Epoch: [0][1950/2503]\tTime  0.110 ( 1.050)\tData  0.000 ( 0.940)\tLoss 6.4592e+00 (6.9125e+00)\tAcc@1   0.59 (  0.45)\tAcc@5   3.52 (  1.92)\n",
      "Epoch: [0][2000/2503]\tTime  0.112 ( 1.050)\tData  0.000 ( 0.941)\tLoss 6.3583e+00 (6.9013e+00)\tAcc@1   0.59 (  0.46)\tAcc@5   3.32 (  1.98)\n",
      "Epoch: [0][2050/2503]\tTime  0.110 ( 1.050)\tData  0.000 ( 0.941)\tLoss 6.4611e+00 (6.8905e+00)\tAcc@1   1.56 (  0.48)\tAcc@5   3.52 (  2.02)\n",
      "Epoch: [0][2100/2503]\tTime  0.110 ( 1.050)\tData  0.000 ( 0.941)\tLoss 6.3957e+00 (6.8799e+00)\tAcc@1   0.59 (  0.49)\tAcc@5   4.49 (  2.07)\n",
      "Epoch: [0][2150/2503]\tTime  0.314 ( 1.050)\tData  0.205 ( 0.941)\tLoss 6.4736e+00 (6.8698e+00)\tAcc@1   0.78 (  0.51)\tAcc@5   4.10 (  2.12)\n",
      "Epoch: [0][2200/2503]\tTime  0.594 ( 1.050)\tData  0.486 ( 0.941)\tLoss 6.4028e+00 (6.8599e+00)\tAcc@1   1.17 (  0.52)\tAcc@5   6.45 (  2.18)\n",
      "Epoch: [0][2250/2503]\tTime  0.308 ( 1.051)\tData  0.200 ( 0.942)\tLoss 6.4114e+00 (6.8502e+00)\tAcc@1   1.17 (  0.54)\tAcc@5   2.73 (  2.23)\n",
      "Epoch: [0][2300/2503]\tTime  0.688 ( 1.051)\tData  0.580 ( 0.942)\tLoss 6.4728e+00 (6.8404e+00)\tAcc@1   0.98 (  0.55)\tAcc@5   3.91 (  2.28)\n",
      "Epoch: [0][2350/2503]\tTime  0.426 ( 1.051)\tData  0.319 ( 0.942)\tLoss 6.4680e+00 (6.8311e+00)\tAcc@1   1.37 (  0.57)\tAcc@5   3.91 (  2.33)\n",
      "Epoch: [0][2400/2503]\tTime  1.075 ( 1.051)\tData  0.967 ( 0.942)\tLoss 6.3370e+00 (6.8216e+00)\tAcc@1   1.56 (  0.58)\tAcc@5   5.08 (  2.39)\n",
      "Epoch: [0][2450/2503]\tTime  2.101 ( 1.051)\tData  1.994 ( 0.942)\tLoss 6.4055e+00 (6.8127e+00)\tAcc@1   1.56 (  0.60)\tAcc@5   4.49 (  2.44)\n",
      "Epoch: [0][2500/2503]\tTime  1.960 ( 1.051)\tData  1.853 ( 0.942)\tLoss 6.3848e+00 (6.8042e+00)\tAcc@1   1.17 (  0.61)\tAcc@5   5.47 (  2.49)\n",
      "Batch size: 512, allocated memory: 20563.091796875 MB total memory: 22592.0625 MB\n",
      "Test: [ 0/98]\tTime  3.424 ( 3.424)\tLoss 5.8052e+00 (5.8052e+00)\tAcc@1   1.95 (  1.95)\tAcc@5  14.45 ( 14.45)\n",
      "Test: [50/98]\tTime  2.099 ( 1.189)\tLoss nan (nan)\tAcc@1   0.78 (  1.09)\tAcc@5   3.12 (  4.47)\n",
      " * Acc@1 1.348 Acc@5 4.806\n",
      "lr: [0.09045084971874738]\n",
      "Epoch: [1][   0/2503]\tTime  2.415 ( 2.415)\tData  2.300 ( 2.300)\tLoss 6.3689e+00 (6.3689e+00)\tAcc@1   1.37 (  1.37)\tAcc@5   4.88 (  4.88)\n",
      "Epoch: [1][  50/2503]\tTime  1.921 ( 1.051)\tData  1.813 ( 0.942)\tLoss 6.3087e+00 (6.3559e+00)\tAcc@1   1.76 (  1.46)\tAcc@5   4.49 (  5.18)\n",
      "Epoch: [1][ 100/2503]\tTime  1.860 ( 1.030)\tData  1.752 ( 0.922)\tLoss 6.2872e+00 (6.3505e+00)\tAcc@1   2.15 (  1.42)\tAcc@5   6.25 (  5.28)\n",
      "Epoch: [1][ 150/2503]\tTime  1.852 ( 1.019)\tData  1.745 ( 0.911)\tLoss 6.2392e+00 (6.3477e+00)\tAcc@1   0.78 (  1.43)\tAcc@5   6.84 (  5.30)\n",
      "Epoch: [1][ 200/2503]\tTime  1.915 ( 1.018)\tData  1.808 ( 0.910)\tLoss 6.3728e+00 (6.3419e+00)\tAcc@1   1.37 (  1.43)\tAcc@5   5.66 (  5.26)\n",
      "Epoch: [1][ 250/2503]\tTime  1.906 ( 1.020)\tData  1.799 ( 0.912)\tLoss 6.3524e+00 (6.3366e+00)\tAcc@1   2.15 (  1.47)\tAcc@5   4.88 (  5.34)\n",
      "Epoch: [1][ 300/2503]\tTime  1.893 ( 1.024)\tData  1.785 ( 0.915)\tLoss 6.2588e+00 (6.3318e+00)\tAcc@1   1.95 (  1.48)\tAcc@5   6.05 (  5.41)\n",
      "Epoch: [1][ 350/2503]\tTime  1.984 ( 1.024)\tData  1.874 ( 0.916)\tLoss 6.3324e+00 (6.3256e+00)\tAcc@1   2.15 (  1.51)\tAcc@5   7.81 (  5.51)\n",
      "Epoch: [1][ 400/2503]\tTime  1.580 ( 1.025)\tData  1.473 ( 0.916)\tLoss 6.3072e+00 (6.3189e+00)\tAcc@1   1.95 (  1.56)\tAcc@5   4.88 (  5.63)\n",
      "Epoch: [1][ 450/2503]\tTime  1.823 ( 1.026)\tData  1.715 ( 0.917)\tLoss 6.3282e+00 (6.3129e+00)\tAcc@1   0.98 (  1.59)\tAcc@5   5.86 (  5.70)\n",
      "Epoch: [1][ 500/2503]\tTime  1.874 ( 1.027)\tData  1.766 ( 0.918)\tLoss 6.2639e+00 (6.3067e+00)\tAcc@1   1.37 (  1.61)\tAcc@5   6.45 (  5.77)\n",
      "Epoch: [1][ 550/2503]\tTime  1.954 ( 1.028)\tData  1.847 ( 0.920)\tLoss 6.1306e+00 (6.3007e+00)\tAcc@1   3.91 (  1.65)\tAcc@5   9.77 (  5.86)\n",
      "Epoch: [1][ 600/2503]\tTime  1.948 ( 1.031)\tData  1.840 ( 0.922)\tLoss 6.1991e+00 (6.2954e+00)\tAcc@1   1.56 (  1.68)\tAcc@5   5.47 (  5.92)\n",
      "Epoch: [1][ 650/2503]\tTime  1.925 ( 1.033)\tData  1.817 ( 0.925)\tLoss 6.2732e+00 (6.2888e+00)\tAcc@1   1.76 (  1.72)\tAcc@5   5.47 (  6.04)\n",
      "Epoch: [1][ 700/2503]\tTime  1.920 ( 1.033)\tData  1.812 ( 0.925)\tLoss 6.2369e+00 (6.2831e+00)\tAcc@1   2.15 (  1.75)\tAcc@5   6.84 (  6.11)\n",
      "Epoch: [1][ 750/2503]\tTime  1.704 ( 1.034)\tData  1.597 ( 0.925)\tLoss 6.2257e+00 (6.2758e+00)\tAcc@1   1.76 (  1.79)\tAcc@5   6.45 (  6.20)\n",
      "Epoch: [1][ 800/2503]\tTime  1.555 ( 1.034)\tData  1.447 ( 0.926)\tLoss 6.1816e+00 (6.2698e+00)\tAcc@1   2.34 (  1.81)\tAcc@5   7.81 (  6.26)\n",
      "Epoch: [1][ 850/2503]\tTime  0.782 ( 1.035)\tData  0.674 ( 0.926)\tLoss 6.1909e+00 (6.2630e+00)\tAcc@1   2.15 (  1.84)\tAcc@5   9.18 (  6.35)\n",
      "Epoch: [1][ 900/2503]\tTime  0.110 ( 1.035)\tData  0.000 ( 0.927)\tLoss 6.1686e+00 (6.2562e+00)\tAcc@1   1.37 (  1.86)\tAcc@5   6.84 (  6.44)\n",
      "Epoch: [1][ 950/2503]\tTime  0.110 ( 1.035)\tData  0.000 ( 0.927)\tLoss 6.1846e+00 (6.2506e+00)\tAcc@1   1.95 (  1.89)\tAcc@5   6.45 (  6.51)\n",
      "Epoch: [1][1000/2503]\tTime  0.110 ( 1.036)\tData  0.000 ( 0.927)\tLoss 6.1800e+00 (6.2438e+00)\tAcc@1   2.93 (  1.92)\tAcc@5   6.45 (  6.59)\n",
      "Epoch: [1][1050/2503]\tTime  0.110 ( 1.036)\tData  0.000 ( 0.928)\tLoss 6.0370e+00 (6.2380e+00)\tAcc@1   2.34 (  1.94)\tAcc@5   8.79 (  6.67)\n",
      "Epoch: [1][1100/2503]\tTime  0.110 ( 1.037)\tData  0.000 ( 0.929)\tLoss 6.1364e+00 (6.2321e+00)\tAcc@1   1.95 (  1.96)\tAcc@5   8.98 (  6.75)\n",
      "Epoch: [1][1150/2503]\tTime  0.110 ( 1.039)\tData  0.000 ( 0.931)\tLoss 6.1439e+00 (6.2251e+00)\tAcc@1   2.15 (  2.00)\tAcc@5   8.01 (  6.84)\n",
      "Epoch: [1][1200/2503]\tTime  0.110 ( 1.039)\tData  0.000 ( 0.931)\tLoss 6.0860e+00 (6.2185e+00)\tAcc@1   2.93 (  2.03)\tAcc@5   9.96 (  6.93)\n",
      "Epoch: [1][1250/2503]\tTime  0.110 ( 1.040)\tData  0.000 ( 0.932)\tLoss 6.0966e+00 (6.2125e+00)\tAcc@1   2.73 (  2.06)\tAcc@5   9.57 (  7.02)\n",
      "Epoch: [1][1300/2503]\tTime  0.109 ( 1.040)\tData  0.000 ( 0.931)\tLoss 6.1039e+00 (6.2073e+00)\tAcc@1   1.17 (  2.09)\tAcc@5   7.23 (  7.10)\n",
      "Epoch: [1][1350/2503]\tTime  0.110 ( 1.040)\tData  0.000 ( 0.932)\tLoss 5.9730e+00 (6.2018e+00)\tAcc@1   2.73 (  2.11)\tAcc@5   9.77 (  7.17)\n",
      "Epoch: [1][1400/2503]\tTime  0.110 ( 1.040)\tData  0.000 ( 0.931)\tLoss 5.9926e+00 (6.1961e+00)\tAcc@1   4.10 (  2.14)\tAcc@5  11.52 (  7.25)\n",
      "Epoch: [1][1450/2503]\tTime  0.110 ( 1.040)\tData  0.000 ( 0.931)\tLoss 6.0055e+00 (6.1903e+00)\tAcc@1   3.71 (  2.17)\tAcc@5  10.94 (  7.33)\n",
      "Epoch: [1][1500/2503]\tTime  0.110 ( 1.040)\tData  0.000 ( 0.931)\tLoss 6.0647e+00 (6.1844e+00)\tAcc@1   2.34 (  2.19)\tAcc@5   7.62 (  7.40)\n",
      "Epoch: [1][1550/2503]\tTime  0.110 ( 1.040)\tData  0.000 ( 0.931)\tLoss 5.9685e+00 (6.1792e+00)\tAcc@1   3.91 (  2.22)\tAcc@5  10.35 (  7.47)\n",
      "Epoch: [1][1600/2503]\tTime  0.110 ( 1.040)\tData  0.000 ( 0.931)\tLoss 5.9533e+00 (6.1742e+00)\tAcc@1   2.93 (  2.25)\tAcc@5  10.55 (  7.54)\n",
      "Epoch: [1][1650/2503]\tTime  0.110 ( 1.040)\tData  0.000 ( 0.932)\tLoss 6.0092e+00 (6.1686e+00)\tAcc@1   4.88 (  2.28)\tAcc@5  12.70 (  7.61)\n",
      "Epoch: [1][1700/2503]\tTime  0.110 ( 1.040)\tData  0.000 ( 0.932)\tLoss 5.9595e+00 (6.1634e+00)\tAcc@1   3.71 (  2.30)\tAcc@5  12.70 (  7.68)\n",
      "Epoch: [1][1750/2503]\tTime  0.110 ( 1.040)\tData  0.000 ( 0.932)\tLoss 6.0905e+00 (6.1580e+00)\tAcc@1   3.12 (  2.33)\tAcc@5   9.96 (  7.75)\n",
      "Epoch: [1][1800/2503]\tTime  0.110 ( 1.040)\tData  0.000 ( 0.932)\tLoss 5.9483e+00 (6.1528e+00)\tAcc@1   3.71 (  2.36)\tAcc@5   9.77 (  7.82)\n",
      "Epoch: [1][1850/2503]\tTime  0.110 ( 1.041)\tData  0.000 ( 0.932)\tLoss 5.9637e+00 (6.1477e+00)\tAcc@1   3.91 (  2.38)\tAcc@5  11.13 (  7.89)\n",
      "Epoch: [1][1900/2503]\tTime  0.109 ( 1.041)\tData  0.000 ( 0.932)\tLoss 6.0069e+00 (6.1428e+00)\tAcc@1   2.73 (  2.41)\tAcc@5   8.79 (  7.96)\n",
      "Epoch: [1][1950/2503]\tTime  0.110 ( 1.041)\tData  0.000 ( 0.932)\tLoss 5.8690e+00 (6.1374e+00)\tAcc@1   2.93 (  2.44)\tAcc@5  11.13 (  8.03)\n",
      "Epoch: [1][2000/2503]\tTime  0.110 ( 1.041)\tData  0.000 ( 0.933)\tLoss 6.0353e+00 (6.1327e+00)\tAcc@1   3.32 (  2.47)\tAcc@5   8.59 (  8.10)\n",
      "Epoch: [1][2050/2503]\tTime  0.110 ( 1.041)\tData  0.000 ( 0.933)\tLoss 5.8849e+00 (6.1279e+00)\tAcc@1   3.71 (  2.50)\tAcc@5  10.94 (  8.16)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(log_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/runs/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(START_EPOCH, EPOCHS):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#adjust_learning_rate(optimizer, epoch)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# train for one epoch\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Check how much GPU memory was used during training\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     allocated_memory \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmax_memory_allocated(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     16\u001b[0m     end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (images, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m# measure data loading time\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         data_time\u001b[38;5;241m.\u001b[39mupdate(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m end)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#         if GPU is not None:\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#             images = images.cuda(GPU, non_blocking=True)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#         if torch.cuda.is_available():\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#             target = target.cuda(GPU, non_blocking=True)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:635\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 635\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:1330\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1330\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1333\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:1286\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1286\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1287\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1288\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:1134\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 306\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a SummaryWriter to log accuracy, loss, and learning rate during training\n",
    "writer = SummaryWriter(log_dir=\"/data/runs/\")\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    #adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # Check how much GPU memory was used during training\n",
    "    allocated_memory = torch.cuda.max_memory_allocated(device=device)\n",
    "    total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "    print(f\"Batch size: {TRAIN_BATCH}, allocated memory: {allocated_memory / 1024 / 1024} MB total memory: {total_memory / 1024 / 1024} MB\")\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "# Close the SummaryWriter\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a16cc1c",
   "metadata": {
    "id": "adc68068"
   },
   "outputs": [],
   "source": [
    "# the logdir should match the parameter passed to what you pass to SummaryWriter, e.g.\n",
    "# writer = SummaryWriter(log_dir=\"/data/runs/\")\n",
    "!tensorboard --logdir=/data/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e67b6",
   "metadata": {
    "id": "d3faf0cd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
